import openai
import json
import time
import os

# === API í‚¤ ì„¤ì • ===
# í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYì— í‚¤ë¥¼ ì„¤ì •í•˜ê±°ë‚˜, ì•„ë˜ì— ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.
api_key = ""
openai.api_key = api_key


# === ë°ì´í„° ê²½ë¡œ ì„¤ì • ===
DATA_PATH = "/Users/hwangjunho/Desktop/model/fintuning_data.json"  # ë³€í™˜ ì „ ì›ë³¸ JSON íŒŒì¼

# === JSON â†’ JSONL ë³€í™˜ í•¨ìˆ˜ ===
def convert_data_for_fine_tuning(input_file, output_file):
    """
    [{"prompt":..., "completion":...}, ...] í¬ë§·ì˜ JSONì„
    {"messages":[{"role":"user",...}, {"role":"assistant",...}]} í˜•íƒœì˜ JSONLë¡œ ë³€í™˜
    """
    print(f"ë°ì´í„° ë³€í™˜ ì¤‘: {input_file} â†’ {output_file}")
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    formatted = []
    for item in data:
        if 'prompt' not in item or 'completion' not in item:
            print(f"[ê²½ê³ ] prompt/completion ëˆ„ë½: {item}")
            continue

        # User ë©”ì‹œì§€ + Assistant ì‘ë‹µ êµ¬ì„±
        messages = [
            {"role": "user", "content": item['prompt'].strip()},
            {"role": "assistant", "content": item['completion'].strip()}
        ]
        formatted.append({"messages": messages})

    # JSONLë¡œ ì €ì¥
    with open(output_file, 'w', encoding='utf-8') as f:
        for entry in formatted:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')

    print(f"ë³€í™˜ ì™„ë£Œ: ì´ {len(formatted)}ê°œ â†’ {output_file}")
    return output_file

# === íŒŒì¼ ì—…ë¡œë“œ ===
def upload_training_file(file_path):
    print(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘: {file_path}")
    resp = openai.File.create(
        file=open(file_path, 'rb'),
        purpose="fine-tune"
    )
    file_id = resp["id"]
    print(f"ì—…ë¡œë“œ ì™„ë£Œ. File ID: {file_id}")
    return file_id

# === íŒŒì¸íŠœë‹ ì‘ì—… ìƒì„± ===
def create_fine_tuning_job(training_file_id, model="gpt-3.5-turbo"):
    print(f"íŒŒì¸íŠœë‹ ì‘ì—… ìƒì„±: model={model}, file={training_file_id}")
    resp = openai.FineTuningJob.create(
        training_file=training_file_id,
        model=model
    )
    job_id = resp.id
    print(f"Job ID: {job_id}")
    return job_id

# === ìƒíƒœ ì¡°íšŒ ===
def check_fine_tuning_status(job_id):
    resp = openai.FineTuningJob.retrieve(job_id)
    status = resp.status
    print(f"[Status] {status}")
    if status == "succeeded":
        print(f"ìƒì„±ëœ ëª¨ë¸ ID: {resp.fine_tuned_model}")
    elif status == "failed":
        print(f"ì‹¤íŒ¨ ì‚¬ìœ : {resp.error}")
    return status, resp

# === ì™„ë£Œ ëŒ€ê¸° ===
def wait_for_fine_tuning_completion(job_id, check_interval=60, max_wait_time=3600):
    elapsed = 0
    while elapsed < max_wait_time:
        status, resp = check_fine_tuning_status(job_id)
        if status in ["succeeded", "failed", "cancelled"]:
            return resp.fine_tuned_model if status == "succeeded" else None
        print(f"{check_interval}ì´ˆ ëŒ€ê¸° í›„ ì¬ì¡°íšŒâ€¦")
        time.sleep(check_interval)
        elapsed += check_interval

    print("[ê²½ê³ ] ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼. ìˆ˜ë™ í™•ì¸ í•„ìš”.")
    return None

# === í…ŒìŠ¤íŠ¸ ìš”ì²­ ===
def test_fine_tuned_model(model_id, prompt):
    print(f"íŒŒì¸íŠœë‹ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸: {model_id}")
    resp = openai.ChatCompletion.create(
        model=model_id,
        messages=[{"role": "user", "content": prompt}],
        max_tokens=500,
        temperature=0.7
    )
    answer = resp.choices[0].message.content
    print("=== í…ŒìŠ¤íŠ¸ ì‘ë‹µ ===")
    print(answer)
    return answer

# === ë©”ì¸ ì‹¤í–‰ ===
def main():
    # 1) JSON â†’ JSONL ë³€í™˜
    jsonl_file = "formatted_training_data.jsonl"
    convert_data_for_fine_tuning(DATA_PATH, jsonl_file)

    # 2) ì—…ë¡œë“œ
    file_id = upload_training_file(jsonl_file)

    # 3) íŒŒì¸íŠœë‹ Job ìƒì„±
    job_id = create_fine_tuning_job(file_id, model="gpt-3.5-turbo")

    # 4) ì™„ë£Œ ëŒ€ê¸°
    model_id = wait_for_fine_tuning_completion(job_id)
    if not model_id:
        print("íŒŒì¸íŠœë‹ ì‹¤íŒ¨ ë˜ëŠ” ì¤‘ë‹¨ë¨.")
        return

    # 5) í…ŒìŠ¤íŠ¸
    test_prompt = "ì´ ê²Œì„ ë£° ì „ì²´ë¥¼ ì²˜ìŒë¶€í„° ëê¹Œì§€ ê°„ë‹¨íˆ ì•Œë ¤ì£¼ì„¸ìš”."
    test_fine_tuned_model(model_id, test_prompt)

    print(f"\nğŸ‰ íŒŒì¸íŠœë‹ ì™„ë£Œ! ìƒˆ ëª¨ë¸ ID: {model_id}")

if __name__ == "__main__":
    main()
