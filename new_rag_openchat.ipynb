{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2866d905-af2a-466f-ae50-57dee32a7f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "Successfully installed pip-25.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (1.24.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy<3.0,>=1.25.0 (from faiss-cpu)\n",
      "  Downloading numpy-2.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (23.2)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu118)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.31.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.3.0)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading faiss_cpu-1.11.0-cp310-cp310-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.31.2-py3-none-any.whl (484 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: typing_extensions, tqdm, threadpoolctl, safetensors, regex, numpy, joblib, fsspec, scipy, huggingface-hub, faiss-cpu, tokenizers, scikit-learn, accelerate, transformers, sentence-transformers\n",
      "\u001b[2K  Attempting uninstall: typing_extensions\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.4.0\n",
      "\u001b[2K    Uninstalling typing_extensions-4.4.0:\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.4.0[32m 0/16\u001b[0m [typing_extensions]\n",
      "\u001b[2K  Attempting uninstall: numpy[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/16\u001b[0m [regex]\n",
      "\u001b[2K    Found existing installation: numpy 1.24.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/16\u001b[0m [regex]\n",
      "\u001b[2K    Uninstalling numpy-1.24.1:\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/16\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.24.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/16\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: fsspec0mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/16\u001b[0m [joblib]\n",
      "\u001b[2K    Found existing installation: fsspec 2023.4.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/16\u001b[0m [joblib]\n",
      "\u001b[2K    Uninstalling fsspec-2023.4.0:\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/16\u001b[0m [joblib]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2023.4.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/16\u001b[0m [fsspec]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/16\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.6.0 faiss-cpu-1.11.0 fsspec-2025.3.2 huggingface-hub-0.31.2 joblib-1.5.0 numpy-2.2.5 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.3 sentence-transformers-4.1.0 threadpoolctl-3.6.0 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3 typing_extensions-4.13.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install faiss-cpu sentence-transformers transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f66a129d-dcf1-468c-a60e-5e7ccfa8107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.26.4\n",
      "Uninstalling numpy-1.26.4:\n",
      "  Successfully uninstalled numpy-1.26.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.24.4\n",
      "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "faiss-cpu 1.11.0 requires numpy<3.0,>=1.25.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip install numpy==1.24.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb22809-4e8a-419a-99f4-ef570d604021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f72c1887154e6db164f5b94403ac27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c887e216bbd402d99ae36525b804cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# âœ… OpenChat ëª¨ë¸ ë¡œë”©\n",
    "model_id = \"openchat/openchat-3.5-0106\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "chat = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=768,\n",
    "    temperature=0.7,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "# âœ… game.json ë¡œë”©\n",
    "with open(\"game.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = [item[\"text\"] for item in data]\n",
    "game_names = [item[\"game_name\"] for item in data]\n",
    "\n",
    "# âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”©\n",
    "embed_model = SentenceTransformer(\"BAAI/bge-m3\", device=\"cuda\")\n",
    "embeddings = embed_model.encode(\n",
    "    texts,\n",
    "    normalize_embeddings=True,\n",
    "    batch_size=8,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# âœ… FAISS ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# âœ… ì¶œë ¥ í›„ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def clean_output(raw_output: str) -> str:\n",
    "    # assistant í† í° ì´í›„ë§Œ ì¶”ì¶œ\n",
    "    if \"<|assistant|>\" in raw_output:\n",
    "        raw_output = raw_output.split(\"<|assistant|>\")[-1]\n",
    "\n",
    "    # \"ì¶”ì²œ ì™„ë£Œ!\" ì´ì „ê¹Œì§€ë§Œ ìœ ì§€\n",
    "    if \"ì¶”ì²œ ì™„ë£Œ!\" in raw_output:\n",
    "        raw_output = raw_output.split(\"ì¶”ì²œ ì™„ë£Œ!\")[0]\n",
    "\n",
    "    return raw_output.strip()\n",
    "\n",
    "# âœ… ì¶”ì²œ í•¨ìˆ˜\n",
    "def recommend_with_openchat(query, default_k=3):\n",
    "    number_match = re.search(r'(\\d+)\\s*ê°œ', query)\n",
    "    top_k = int(number_match.group(1)) if number_match else default_k\n",
    "\n",
    "    # ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "    query_embedding = embed_model.encode([query], normalize_embeddings=True)\n",
    "    D, I = index.search(np.array(query_embedding), k=top_k)\n",
    "\n",
    "    # ê²€ìƒ‰ ê²°ê³¼ â†’ í”„ë¡¬í”„íŠ¸ êµ¬ì„±ìš©\n",
    "    retrieved = []\n",
    "    selected_names = []\n",
    "    for i in I[0]:\n",
    "        name = game_names[i]\n",
    "        desc = texts[i]\n",
    "        retrieved.append(f\"[{name}]\\n{desc}\")\n",
    "        selected_names.append(f\"- {name}\")\n",
    "\n",
    "    context = \"\\n\\n\".join(retrieved)\n",
    "    name_list_str = \"\\n\".join(selected_names)\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸\n",
    "    prompt = f\"\"\"ì•„ë˜ëŠ” ë³´ë“œê²Œì„ ì„¤ëª…ì…ë‹ˆë‹¤. ê° ê²Œì„ì€ \"[ê²Œì„ëª…]\\nì„¤ëª…\" í˜•ì‹ìœ¼ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "[ê²Œì„ ì„¤ëª…]\n",
    "{context}\n",
    "\n",
    "âš ï¸ ë°˜ë“œì‹œ ì•„ë˜ì˜ ê²Œì„ ì´ë¦„ ëª©ë¡ ì¤‘ì—ì„œë§Œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ëª©ë¡ì— ì—†ëŠ” ê²Œì„ ì´ë¦„ì„ ì ˆëŒ€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.  \n",
    "ë§Œì•½ ëª©ë¡ì— ì—†ëŠ” ê²Œì„ëª…ì„ ì¶œë ¥í•˜ë©´ ì‹¤íŒ¨ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.\n",
    "\n",
    "[í—ˆìš©ëœ ê²Œì„ ì´ë¦„ ëª©ë¡]\n",
    "{ name_list_str }\n",
    "\n",
    "[ì‚¬ìš©ì ì§ˆë¬¸]\n",
    "{query}\n",
    "\n",
    "ğŸ“Œ ì¶œë ¥ ì§€ì¹¨:\n",
    "- ë°˜ë“œì‹œ ìœ„ ëª©ë¡ì— ìˆëŠ” ê²Œì„ ì¤‘ì—ì„œë§Œ 3ê°œë¥¼ ê³¨ë¼ ì¶”ì²œí•˜ì„¸ìš”.\n",
    "- ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì²˜ëŸ¼ ì‘ì„±í•˜ì„¸ìš”:\n",
    "\n",
    "ê²Œì„ëª…1: ì¶”ì²œ ì´ìœ   \n",
    "ê²Œì„ëª…2: ì¶”ì²œ ì´ìœ   \n",
    "ê²Œì„ëª…3: ì¶”ì²œ ì´ìœ \n",
    "\n",
    "- ê° ì¤„ì€ 'ê²Œì„ëª…: ì¶”ì²œ ì´ìœ ' í˜•ì‹ìœ¼ë¡œë§Œ ì‘ì„±í•˜ê³ , ì¤„ë°”ê¿ˆ ì´ì™¸ì— ì•„ë¬´ í¬ë§·ë„ ì“°ì§€ ë§ˆì„¸ìš”.\n",
    "- ì¶”ì²œì´ ëª¨ë‘ ëë‚˜ë©´ ë§ˆì§€ë§‰ ì¤„ì— ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì´ ì¨ì£¼ì„¸ìš”:  \n",
    "ì¶”ì²œ ì™„ë£Œ!\n",
    "\n",
    "ê·¸ ì´í›„ì—ëŠ” ì•„ë¬´ ê²ƒë„ ì“°ì§€ ë§ˆì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "    chat_prompt = f\"<|system|>\\në„ˆëŠ” ë³´ë“œê²Œì„ ì¶”ì²œ ë„ìš°ë¯¸ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë”°ë¼ ê´€ë ¨ ê²Œì„ì„ ì¶”ì²œí•˜ê³  ì´ìœ ë„ ì•Œë ¤ì¤˜.\\n<|user|>\\n{prompt}\\n<|assistant|>\"\n",
    "    raw_output = chat(chat_prompt)[0][\"generated_text\"]\n",
    "    cleaned = clean_output(raw_output)\n",
    "\n",
    "    print(\"\\nğŸ¤– ì¶”ì²œê²Œì„ (OpenChat ê¸°ë°˜):\\n\")\n",
    "    print(cleaned)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3362818e-8ca9-44fc-a57e-ea0321400f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ² ë³´ë“œê²Œì„ ì¶”ì²œ ì‹œìŠ¤í…œ (OpenChat ê¸°ë°˜)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "â“ ì–´ë–¤ ê²Œì„ì„ ì›í•˜ì‹œë‚˜ìš”?\n",
      "ì˜ˆì‹œ: 'ì „ëµì ì´ê³  ë¹ ë¥¸ ê²Œì„ 3ê°œ ì¶”ì²œí•´ì¤˜'\n",
      ">  ì „ëµì ì´ê³  ë¹ ë¥¸ ê²Œì„ 3ê°œ ì¶”ì²œí•´ì¤˜\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¤– ì¶”ì²œê²Œì„ (OpenChat ê¸°ë°˜):\n",
      "\n",
      "ê²Œì„ëª…1: ì‡¼í…í† í…  \n",
      "ì¶”ì²œ ì´ìœ : ì‡¼í…í† í…ì€ ì „ëµì ìœ¼ë¡œ ìƒê°í•˜ê³  ë¹ ë¥¸ ê²Œì„ì…ë‹ˆë‹¤. ê²Œì„ì˜ ëª©í‘œëŠ” ìì‹ ì´ ì†í•œ íŒ€ì´ ìƒëŒ€ íŒ€ì—ê²Œ ê°€ì¥ ë§ì€ ëŒì„ ë¹¼ì•„ ê°€ëŠ” ê²ƒì…ë‹ˆë‹¤. ê° í„´ì— ëŒì„ ë¹¼ëŠ” ë°©ë²•ì€ ë‹¤ì–‘í•˜ê²Œ ìƒê°í•´ì•¼ í•˜ë©°, ì „ëµì„ ì„¸ìš°ê³  ì‹¤í–‰í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê²Œì„ëª…2: ì–¸ë½  \n",
      "ì¶”ì²œ ì´ìœ : ì–¸ë½ì€ ì „ëµì ì´ê³  ë¹ ë¥¸ ê²Œì„ìœ¼ë¡œ, ì‹œë‚˜ë¦¬ì˜¤ ì¢…ë¥˜ë§ˆë‹¤ ë‹¤ë¥¸ ì´ì•¼ê¸°ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ê²Œì„ì˜ ëª©í‘œëŠ” ì„ íƒí•œ ì‹œë‚˜ë¦¬ì˜¤ì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ, ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ìì‹ ì˜ íŒ€ì´ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ê²Œì„ ì§„í–‰ì— ìˆì–´ ì „ëµì„ ì„¸ìš°ê³  ì‹¤í–‰í•˜ëŠ” ê²ƒì´ í•„ìš”í•˜ë©°, ë¹ ë¥´ê²Œ ê°€ìƒ ì„¸ìƒì—ì„œ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ ë‚˜ê°‘ë‹ˆë‹¤.\n",
      "\n",
      "ê²Œì„ëª…3: ë±…  \n",
      "ì¶”ì²œ ì´ìœ : ë±…ì€ ì „ëµì ì´ê³  ë¹ ë¥¸ ê²Œì„ìœ¼ë¡œ, ë¬´ë²•ì, ë¶€ê´€, ë°°ì‹ ì, ë³´ì•ˆê´€ ì¤‘ í•˜ë‚˜ê°€ ë˜ì–´ ëª©í‘œë¥¼ ì´ë£¨ëŠ” ê²ƒì´ ê²Œì„ì˜ ëª©í‘œì…ë‹ˆë‹¤. ê²Œì„ ì§„í–‰ì— ìˆì–´ ë‹¤ë¥¸ í”Œë ˆì´ì–´ë“¤ì˜ í–‰ë™ì„ ì¶”ì í•˜ê³  ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, ì „ëµì„ ì„¸ìš°ê³  ì‹¤í–‰í•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤. ë¹ ë¥¸ ì†ë„ë¡œ ê²Œì„ì„ ì§„í–‰í•˜ë©´ì„œë„ ì „ëµì„ ì„¸ìš°ê³  ì‹¤í–‰í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ëŠ” ì ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# âœ… ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸ² ë³´ë“œê²Œì„ ì¶”ì²œ ì‹œìŠ¤í…œ (OpenChat ê¸°ë°˜)\")\n",
    "    user_query = input(\"â“ ì–´ë–¤ ê²Œì„ì„ ì›í•˜ì‹œë‚˜ìš”?\\nì˜ˆì‹œ: 'ì „ëµì ì´ê³  ë¹ ë¥¸ ê²Œì„ 3ê°œ ì¶”ì²œí•´ì¤˜'\\n> \")\n",
    "    recommend_with_openchat(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0cfcd7-23bb-4255-ac1b-4c3dd9a43549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
